import { __awaiter, __extends, __generator } from "tslib";
import { getGUID, isFunc, stringIsNullOrEmpty } from "@pnp/common";
import { ODataParser, extendFactory, headers } from "@pnp/odata";
import { File, Files } from "@pnp/sp/files/index.js";
import { spPost, odataUrlFrom, escapeQueryStrValue } from "@pnp/sp";
var StreamParser = /** @class */ (function (_super) {
    __extends(StreamParser, _super);
    function StreamParser() {
        return _super !== null && _super.apply(this, arguments) || this;
    }
    StreamParser.prototype.parseImpl = function (r, resolve) {
        resolve({ body: r.body, knownLength: parseInt(r.headers.get("content-length"), 10) });
    };
    return StreamParser;
}(ODataParser));
export { StreamParser };
extendFactory(File, {
    getStream: function () {
        return this.clone(File, "$value", false).usingParser(new StreamParser())(headers({ "binaryStringResponseBody": "true" }));
    },
    /**
     * Sets the contents of a file using a chunked upload approach. Not supported in batching.
     *
     * @param stream The file to upload (as readable stream)
     * @param progress A callback function which can be used to track the progress of the upload
     * @param chunkSize The size of each file chunks, in bytes (default: 10485760)
     */
    setStreamContentChunked: function (stream, progress, chunkSize) {
        if (chunkSize === void 0) { chunkSize = 10485760; }
        return __awaiter(this, void 0, void 0, function () {
            var uploadId, blockNumber, currentPointer, fileSize, totalBlocks, chunkBuffer;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        if (!isFunc(progress)) {
                            progress = function () { return null; };
                        }
                        uploadId = getGUID();
                        blockNumber = 1;
                        currentPointer = 0;
                        fileSize = null;
                        totalBlocks = null;
                        chunkBuffer = null;
                        _a.label = 1;
                    case 1:
                        if (!(null !== (chunkBuffer = stream.read(chunkSize)))) return [3 /*break*/, 6];
                        if (!(currentPointer === 0)) return [3 /*break*/, 3];
                        progress({ uploadId: uploadId, blockNumber: blockNumber, chunkSize: chunkSize, currentPointer: currentPointer, fileSize: fileSize, stage: "starting", totalBlocks: totalBlocks });
                        return [4 /*yield*/, this.startUpload(uploadId, chunkBuffer)];
                    case 2:
                        _a.sent();
                        return [3 /*break*/, 5];
                    case 3:
                        progress({ uploadId: uploadId, blockNumber: blockNumber, chunkSize: chunkSize, currentPointer: currentPointer, fileSize: fileSize, stage: "continue", totalBlocks: totalBlocks });
                        return [4 /*yield*/, this.continueUpload(uploadId, currentPointer, chunkBuffer)];
                    case 4:
                        _a.sent();
                        _a.label = 5;
                    case 5:
                        blockNumber += 1;
                        currentPointer += chunkBuffer.length;
                        return [3 /*break*/, 1];
                    case 6:
                        progress({ uploadId: uploadId, blockNumber: blockNumber, chunkSize: chunkSize, currentPointer: currentPointer, fileSize: fileSize, stage: "finishing", totalBlocks: totalBlocks });
                        return [2 /*return*/, this.finishUpload(uploadId, currentPointer, Buffer.from([]))];
                }
            });
        });
    },
});
extendFactory(Files, {
    /**
     * Uploads a file. Not supported for batching
     *
     * @param url The folder-relative url of the file
     * @param content The Blob file content or File readable stream to add
     * @param progress A callback function which can be used to track the progress of the upload
     * @param shouldOverWrite Should a file with the same name in the same location be overwritten? (default: true)
     * @param chunkSize The size of each file slice, in bytes (default: 10485760)
     * @returns The new File and the raw response.
     */
    // @tag("fis.addChunked")
    addChunked: function (url, content, progress, shouldOverWrite, chunkSize) {
        if (shouldOverWrite === void 0) { shouldOverWrite = true; }
        if (chunkSize === void 0) { chunkSize = 10485760; }
        return __awaiter(this, void 0, void 0, function () {
            var response, odataUrl, file;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0: return [4 /*yield*/, spPost(this.clone(Files, "add(overwrite=" + shouldOverWrite + ",url='" + escapeQueryStrValue(url) + "')", false))];
                    case 1:
                        response = _a.sent();
                        odataUrl = odataUrlFrom(response);
                        if (!stringIsNullOrEmpty(odataUrl) && /%27/i.test(odataUrl)) {
                            odataUrl = odataUrl.replace(/%27/ig, "''");
                        }
                        file = File(odataUrl);
                        if ("function" === typeof content.read) {
                            return [2 /*return*/, file.setStreamContentChunked(content, progress, chunkSize)];
                        }
                        return [2 /*return*/, file.setContentChunked(content, progress, chunkSize)];
                }
            });
        });
    },
});
//# sourceMappingURL=stream.js.map