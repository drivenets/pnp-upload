"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.StreamParser = void 0;
var tslib_1 = require("tslib");
var common_1 = require("@pnp/common-commonjs");
var odata_1 = require("@pnp/odata-commonjs");
var index_js_1 = require("@pnp/sp-commonjs/files/index.js");
var sp_1 = require("@pnp/sp-commonjs");
var StreamParser = /** @class */ (function (_super) {
    (0, tslib_1.__extends)(StreamParser, _super);
    function StreamParser() {
        return _super !== null && _super.apply(this, arguments) || this;
    }
    StreamParser.prototype.parseImpl = function (r, resolve) {
        resolve({ body: r.body, knownLength: parseInt(r.headers.get("content-length"), 10) });
    };
    return StreamParser;
}(odata_1.ODataParser));
exports.StreamParser = StreamParser;
(0, odata_1.extendFactory)(index_js_1.File, {
    getStream: function () {
        return this.clone(index_js_1.File, "$value", false).usingParser(new StreamParser())((0, odata_1.headers)({ "binaryStringResponseBody": "true" }));
    },
    /**
     * Sets the contents of a file using a chunked upload approach. Not supported in batching.
     *
     * @param stream The file to upload (as readable stream)
     * @param progress A callback function which can be used to track the progress of the upload
     * @param chunkSize The size of each file chunks, in bytes (default: 10485760)
     */
    setStreamContentChunked: function (stream, progress, chunkSize) {
        if (chunkSize === void 0) { chunkSize = 10485760; }
        return (0, tslib_1.__awaiter)(this, void 0, void 0, function () {
            var uploadId, blockNumber, currentPointer, fileSize, totalBlocks, chunkBuffer;
            return (0, tslib_1.__generator)(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        if (!(0, common_1.isFunc)(progress)) {
                            progress = function () { return null; };
                        }
                        uploadId = (0, common_1.getGUID)();
                        blockNumber = 1;
                        currentPointer = 0;
                        fileSize = null;
                        totalBlocks = null;
                        chunkBuffer = null;
                        _a.label = 1;
                    case 1:
                        if (!(null !== (chunkBuffer = stream.read(chunkSize)))) return [3 /*break*/, 6];
                        if (!(currentPointer === 0)) return [3 /*break*/, 3];
                        progress({ uploadId: uploadId, blockNumber: blockNumber, chunkSize: chunkSize, currentPointer: currentPointer, fileSize: fileSize, stage: "starting", totalBlocks: totalBlocks });
                        return [4 /*yield*/, this.startUpload(uploadId, chunkBuffer)];
                    case 2:
                        _a.sent();
                        return [3 /*break*/, 5];
                    case 3:
                        progress({ uploadId: uploadId, blockNumber: blockNumber, chunkSize: chunkSize, currentPointer: currentPointer, fileSize: fileSize, stage: "continue", totalBlocks: totalBlocks });
                        return [4 /*yield*/, this.continueUpload(uploadId, currentPointer, chunkBuffer)];
                    case 4:
                        _a.sent();
                        _a.label = 5;
                    case 5:
                        blockNumber += 1;
                        currentPointer += chunkBuffer.length;
                        return [3 /*break*/, 1];
                    case 6:
                        progress({ uploadId: uploadId, blockNumber: blockNumber, chunkSize: chunkSize, currentPointer: currentPointer, fileSize: fileSize, stage: "finishing", totalBlocks: totalBlocks });
                        return [2 /*return*/, this.finishUpload(uploadId, currentPointer, Buffer.from([]))];
                }
            });
        });
    },
});
(0, odata_1.extendFactory)(index_js_1.Files, {
    /**
     * Uploads a file. Not supported for batching
     *
     * @param url The folder-relative url of the file
     * @param content The Blob file content or File readable stream to add
     * @param progress A callback function which can be used to track the progress of the upload
     * @param shouldOverWrite Should a file with the same name in the same location be overwritten? (default: true)
     * @param chunkSize The size of each file slice, in bytes (default: 10485760)
     * @returns The new File and the raw response.
     */
    // @tag("fis.addChunked")
    addChunked: function (url, content, progress, shouldOverWrite, chunkSize) {
        if (shouldOverWrite === void 0) { shouldOverWrite = true; }
        if (chunkSize === void 0) { chunkSize = 10485760; }
        return (0, tslib_1.__awaiter)(this, void 0, void 0, function () {
            var response, odataUrl, file;
            return (0, tslib_1.__generator)(this, function (_a) {
                switch (_a.label) {
                    case 0: return [4 /*yield*/, (0, sp_1.spPost)(this.clone(index_js_1.Files, "add(overwrite=" + shouldOverWrite + ",url='" + (0, sp_1.escapeQueryStrValue)(url) + "')", false))];
                    case 1:
                        response = _a.sent();
                        odataUrl = (0, sp_1.odataUrlFrom)(response);
                        if (!(0, common_1.stringIsNullOrEmpty)(odataUrl) && /%27/i.test(odataUrl)) {
                            odataUrl = odataUrl.replace(/%27/ig, "''");
                        }
                        file = (0, index_js_1.File)(odataUrl);
                        if ("function" === typeof content.read) {
                            return [2 /*return*/, file.setStreamContentChunked(content, progress, chunkSize)];
                        }
                        return [2 /*return*/, file.setContentChunked(content, progress, chunkSize)];
                }
            });
        });
    },
});
//# sourceMappingURL=stream.js.map